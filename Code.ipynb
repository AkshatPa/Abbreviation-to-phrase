{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Untitled7.ipynb","provenance":[{"file_id":"1KxBUJKTTgrVgifV3qgSapYZVNPsGfafw","timestamp":1626365326804}],"collapsed_sections":[],"authorship_tag":"ABX9TyOy7Vl2Hfs8Qd8godoW81Wj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Ubhs5nC6eddr"},"source":["\n","from collections import defaultdict, Counter\n","import numpy as np\n","import pandas as pd\n","\n","class LanguageNgramModel:\n","  \n","    def __init__(self, order=1, smoothing=1.0, recursive=0.001):\n","        self.order = order\n","        self.smoothing = smoothing\n","        self.recursive = recursive\n","    \n","    def fit(self, corpus):\n","      \n","        self.counter_ = defaultdict(lambda: Counter())\n","        self.vocabulary_ = set()\n","        for i, token in enumerate(corpus[self.order:]):\n","            context = corpus[i:(i+self.order)]\n","            self.counter_[context][token] += 1\n","            self.vocabulary_.add(token)\n","        self.vocabulary_ = sorted(list(self.vocabulary_))\n","        if self.recursive > 0 and self.order > 0:\n","            self.child_ = LanguageNgramModel(self.order-1, self.smoothing, self.recursive)\n","            self.child_.fit(corpus)\n","            \n","    def get_counts(self, context):\n","    \n","        if self.order:\n","            local = context[-self.order:]\n","        else:\n","            local = ''\n","        freq_dict = self.counter_[local]\n","        freq = pd.Series(index=self.vocabulary_)\n","        for i, token in enumerate(self.vocabulary_):\n","            freq[token] = freq_dict[token] + self.smoothing\n","        if self.recursive > 0 and self.order > 0:\n","            child_freq = self.child_.get_counts(context) * self.recursive\n","            freq += child_freq\n","        return freq\n","    \n","    def predict_proba(self, context):\n","\n","        counts = self.get_counts(context)\n","        return counts / counts.sum()\n","    \n","    def single_log_proba(self, context, continuation):\n"," \n","        result = 0.0\n","        for token in continuation:\n","            result += np.log(self.predict_proba(context)[token])\n","            context += token\n","        return result\n","    \n","    def single_proba(self, context, continuation):\n","\n","        return np.exp(self.single_log_proba(context, continuation))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uhFRMpxjezAJ","executionInfo":{"status":"ok","timestamp":1626272599368,"user_tz":-330,"elapsed":431,"user":{"displayName":"Akshat Patidar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDDgvsABFHIT01IK3wNbCQkoxZiu93dgj9GR1cTg=s64","userId":"05137998957740569636"}},"outputId":"c56a3748-db36-4e2c-a1a4-45fccc2487e7"},"source":["class MissingLetterModel:\n","  \n","    def __init__(self, order=0, smoothing_missed=0.3, smoothing_total=1.0):\n","        self.order = order\n","        self.smoothing_missed = smoothing_missed\n","        self.smoothing_total = smoothing_total\n","    \n","    def fit(self, sentence_pairs):\n","     \n","        self.missed_counter_ = defaultdict(lambda: Counter())\n","        self.total_counter_ = defaultdict(lambda: Counter())\n","        for (original, observed) in sentence_pairs:\n","            for i, (original_letter, observed_letter) \\\n","                    in enumerate(zip(original[self.order:], observed[self.order:])):\n","                context = original[i:(i+self.order)]\n","                if observed_letter == '-':\n","                    self.missed_counter_[context][original_letter] += 1\n","                self.total_counter_[context][original_letter] += 1 \n","    \n","    def predict_proba(self, context, last_letter):\n","\n","        if self.order:\n","            local = context[-self.order:]\n","        else:\n","            local = ''\n","        missed_freq = self.missed_counter_[local][last_letter] + self.smoothing_missed\n","        total_freq = self.total_counter_[local][last_letter] + self.smoothing_total\n","        return missed_freq / total_freq\n","    \n","    def single_log_proba(self, context, continuation, actual=None):\n","    \n","        if not actual:\n","            actual = continuation\n","        result = 0.0\n","        for orig_token, act_token in zip(continuation, actual):\n","            pp = self.predict_proba(context, orig_token)\n","            if act_token != '-':\n","                pp = 1 - pp\n","            result += np.log(pp)\n","            context += orig_token\n","        return result\n","    \n","    def single_proba(self, context, continuation, actual=None):\n","     \n","        return np.exp(self.single_log_proba(context, continuation, actual))\n","\n","lang_model = LanguageNgramModel(1)\n","lang_model.fit(' abracadabra ')\n","print(lang_model.predict_proba(' bra'))\n","\n","missed_model = MissingLetterModel(0)\n","missed_model.fit([('abracadabra', 'abr-c-d-br-')]) \n","\n","print({letter: missed_model.predict_proba('abr', letter) for letter in 'abc'})\n","\n","\n","print(missed_model.single_proba('', 'abra', 'abr-'))\n","\n","np.log10(27) * 10\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["     0.181777\n","a    0.091297\n","b    0.272529\n","c    0.181686\n","d    0.181686\n","r    0.091025\n","dtype: float64\n","{'a': 0.7166666666666667, 'b': 0.09999999999999999, 'c': 0.15}\n","0.16447499999999998\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["14.313637641589875"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gycNScFzfQjD","executionInfo":{"status":"ok","timestamp":1626272607220,"user_tz":-330,"elapsed":695,"user":{"displayName":"Akshat Patidar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDDgvsABFHIT01IK3wNbCQkoxZiu93dgj9GR1cTg=s64","userId":"05137998957740569636"}},"outputId":"b0a0803c-29ce-480a-d3ab-d8be99d45d05"},"source":["\n","from heapq import heappush, heappop\n","\n","def generate_options(prefix_proba, prefix, suffix, \n","                     lang_model, missed_model, optimism=0.5, cache=None):\n","   \n","    options = []\n","    for letter in lang_model.vocabulary_ + ['']:\n","        if letter:  # here we assume the character was missing\n","            next_letter = letter\n","            new_suffix = suffix\n","            new_prefix = prefix + next_letter\n","            proba_missing_state = - np.log(missed_model.predict_proba(prefix, letter))\n","        else:  # here we assume there was no missing character\n","            next_letter = suffix[0]\n","            new_suffix = suffix[1:]\n","            new_prefix = prefix + next_letter\n","            proba_missing_state = - np.log((1 - missed_model.predict_proba(prefix, next_letter)))\n","        proba_next_letter = - np.log(lang_model.single_proba(prefix, next_letter))\n","        if cache:\n","            proba_suffix = cache[len(new_suffix)] * optimism\n","        else:\n","            proba_suffix = - np.log(lang_model.single_proba(new_prefix, new_suffix)) * optimism\n","        proba = prefix_proba + proba_next_letter + proba_missing_state + proba_suffix\n","        options.append((proba, new_prefix, new_suffix, letter, proba_suffix))\n","    return options\n","\n","print(generate_options(0, ' ', 'brac ', lang_model, missed_model))\n","\n","\n","def noisy_channel(word, lang_model, missed_model, freedom=3.0, \n","                  max_attempts=10000, optimism=0.9, verbose=False):\n","\n","    query = word + ' '\n","    prefix = ' '\n","    prefix_proba = 0.0\n","    suffix = query\n","    full_origin_logprob = -lang_model.single_log_proba(prefix, query)\n","    no_missing_logprob = -missed_model.single_log_proba(prefix, query)\n","    best_logprob = full_origin_logprob + no_missing_logprob\n","    # add an empty prefix to the heap\n","    heap = [(best_logprob * optimism, prefix, suffix, '', best_logprob * optimism)]\n","    # add the default candidate (without missing characters) \n","    candidates = [(best_logprob, prefix + query, '', None, 0.0)]\n","    if verbose:\n","        print('baseline score is', best_logprob)\n","    # prepare storage of the phrase suffix probabilities\n","    cache = {}\n","    for i in range(len(query)+1):\n","        future_suffix = query[:i]\n","        cache[len(future_suffix)] = -lang_model.single_log_proba('', future_suffix) # rough approximation\n","        cache[len(future_suffix)] += -missed_model.single_log_proba('', future_suffix) # at least add missingness\n","    \n","    for i in range(max_attempts):\n","        if not heap:\n","            break\n","        next_best = heappop(heap)\n","        if verbose:\n","            print(next_best)\n","        if next_best[2] == '':  # the phrase is fully decoded\n","            # if the phrase is good enough, add it to the answer\n","            if next_best[0] <= best_logprob + freedom:\n","                candidates.append(next_best)\n","                # update estimate of the best likelihood\n","                if next_best[0] < best_logprob:\n","                    best_logprob = next_best[0]\n","        else: # # the phrase is not fully decoded - generate more options\n","            prefix_proba = next_best[0] - next_best[4] # all proba estimate minus suffix\n","            prefix = next_best[1]\n","            suffix = next_best[2]\n","            new_options = generate_options(\n","                prefix_proba, prefix, suffix, lang_model, \n","                missed_model, optimism, cache)\n","            # add only the solution potentioally no worse than the best + freedom\n","            for new_option in new_options: \n","                if new_option[0] < best_logprob + freedom:\n","                    heappush(heap, new_option)\n","    if verbose:\n","        print('heap size is', len(heap), 'after', i, 'iterations')\n","    result = {}\n","    for candidate in candidates:\n","        if candidate[0] <= best_logprob + freedom:\n","            result[candidate[1][1:-1]] = candidate[0]\n","    return result\n","\n","\n","result = noisy_channel('brc', lang_model, missed_model, verbose=True, freedom=1)\n","print(result)\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[(6.929663174828117, '  ', 'brac ', ' ', 3.7800651217336947), (5.042879645338754, ' a', 'brac ', 'a', 3.4572571306016755), (8.09487194753453, ' b', 'brac ', 'b', 3.846661605771999), (7.623807861705187, ' c', 'brac ', 'c', 3.7800651217336947), (7.623807861705187, ' d', 'brac ', 'd', 3.7800651217336947), (8.09487194753453, ' r', 'brac ', 'r', 3.846661605771999), (4.858238261775765, ' b', 'rac ', '', 2.8072524973494524)]\n","baseline score is 7.683183062275049\n","(6.914864756047544, ' ', 'brc ', '', 6.914864756047544)\n","(6.755450684372974, ' b', 'rc ', '', 4.704464919946662)\n","(5.824911949460505, ' br', 'c ', '', 2.686363732552668)\n","(7.088440394887126, ' brc', ' ', '', 1.7075575253192956)\n","(7.139259830483152, ' bra', 'c ', 'a', 2.686363732552668)\n","(7.68318306227505, ' brc ', '', '', -0.0)\n","(8.028446927360166, ' brac', ' ', '', 1.7075575253192956)\n","(8.362157608120238, ' a', 'brc ', 'a', 6.776535093383159)\n","(7.695457216846014, ' ab', 'rc ', '', 4.704464919946662)\n","(6.764918481933545, ' abr', 'c ', '', 2.686363732552668)\n","(8.028446927360166, ' abrc', ' ', '', 1.7075575253192956)\n","(8.079266362956194, ' abra', 'c ', 'a', 2.686363732552668)\n","(8.62318959474809, ' abrc ', '', '', -0.0)\n","(8.62318959474809, ' brac ', '', '', -0.0)\n","(8.674062909624206, ' brca', ' ', 'a', 1.7075575253192956)\n","heap size is 0 after 15 iterations\n","{'brc': 7.68318306227505, 'abrc': 8.62318959474809, 'brac': 8.62318959474809}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":73},"id":"h7py3cKniQAt","executionInfo":{"status":"ok","timestamp":1626040041310,"user_tz":-330,"elapsed":59355,"user":{"displayName":"Akshat Patidar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDDgvsABFHIT01IK3wNbCQkoxZiu93dgj9GR1cTg=s64","userId":"05137998957740569636"}},"outputId":"ce99d2fd-8436-4488-d869-6f79ae81bcb9"},"source":["from google.colab import files\n","\n","uploaded = files.upload()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-647b6ba9-15c9-4da1-83ca-9c09b013568c\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-647b6ba9-15c9-4da1-83ca-9c09b013568c\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving 01 - The Fellowship Of The Ring.txt to 01 - The Fellowship Of The Ring.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vQgd0LvCfqxg"},"source":["import re\n","# read the text\n","with open('/content/infosys-ar-21.txt', encoding = \"ISO-8859-1\") as f:\n","    text = f.read()\n","# leave only letters and spaces in the text\n","text2 = re.sub(r'[^a-z ]+', '', text.lower().replace('\\n', ' '))\n","all_letters = ''.join(list(sorted(list(set(text2)))))\n","print(repr(all_letters)) # ' abcdefghijklmnopqrstuvwxyz'\n","# Prepare training sample for the abbreviation model \n","missing_set =  (\n","    [(all_letters, '-' * len(all_letters))] * 3 # all chars missing\n","    + [(all_letters, all_letters)] * 10 # all chars are NOT missing\n","    + [('aeiouy', '------')] * 30 # only vowels are missing\n",")\n","# Train the both models\n","big_lang_m = LanguageNgramModel(order=4, smoothing=0.001, recursive=0.01)\n","big_lang_m.fit(text2)\n","big_err_m = MissingLetterModel(order=0, smoothing_missed=0.1)\n","big_err_m.fit(missing_set)\n","\n","\n","for i in range(5):\n","    tmp = LanguageNgramModel(i, 0.001, 0.01)\n","    tmp.fit(text2[0:-5000])\n","    print(i, tmp.single_log_proba(' ', text2[-5000:]))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GUxKta1sdsHo","executionInfo":{"status":"ok","timestamp":1626277167575,"user_tz":-330,"elapsed":85977,"user":{"displayName":"Akshat Patidar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDDgvsABFHIT01IK3wNbCQkoxZiu93dgj9GR1cTg=s64","userId":"05137998957740569636"}},"outputId":"d12146a8-c1b9-47a4-cfae-74eea134ef7e"},"source":["noisy_channel('ifsy', big_lang_m, big_err_m)\n","\n","noisy_channel('rvn', big_lang_m, big_err_m)\n","\n","noisy_channel('opngblnc', big_lang_m, big_err_m)\n","\n","noisy_channel('drvt', big_lang_m, big_err_m)\n","\n","noisy_channel('fnclassts', big_lang_m, big_err_m)\n","\n","noisy_channel('dprctn', big_lang_m, big_err_m)\n","\n","print(noisy_channel('blnc', big_lang_m, big_err_m))\n","\n","print(noisy_channel('dvdnd', big_lang_m, big_err_m, freedom=5))\n","\n","print(noisy_channel('lblts', big_lang_m, big_err_m, freedom=5))\n","\n","part = text[10502:11149]\n","result = ''\n","for i, letter in enumerate(part):\n","    if np.random.rand() * 0.5 < big_err_m.single_proba(part[0:i], letter):\n","        result += letter\n","print(result)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"],"name":"stderr"},{"output_type":"stream","text":["{'balance': 9.554093699594214}\n","{'dividend': 11.475488678567428, 'dividend ': 14.738236263601777, 'dividends': 13.894727405636457}\n","{'liabilities': 10.272056457979586, 'liabilities ': 13.596525807258878}\n","\n","This year to appointment as at march   flucture company is requity inc designificational asset the preferred to joining busing any below hedge volune with and key member  exercise during its at of the difference received to to the trusts our yrealize our emainik satisfyiness methods and financial as and exte.\n"],"name":"stdout"}]}]}